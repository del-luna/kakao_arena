{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "from scipy import sparse\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 140 ms, total: 1.7 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FILE_PATH = '../data/'\n",
    "\n",
    "train = pd.read_json(FILE_PATH+'train.json', typ = 'frame')\n",
    "test = pd.read_json(FILE_PATH+'test.json', typ = 'frame')\n",
    "val = pd.read_json(FILE_PATH+'val.json', typ = 'frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 78.9 ms, total: 2.21 s\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "row, col, data = [], [], []\n",
    "\n",
    "for idx, playlist in enumerate(train['songs'].to_numpy()):\n",
    "    row += [idx]*len(playlist)\n",
    "    col += playlist\n",
    "    data += [1]*len(playlist)\n",
    "\n",
    "data = sparse.csr_matrix((data, (row, col)))\n",
    "\n",
    "#playlists-songs matrix 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f36757a7afe4e19a76cc8075af917a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wrmf = ALS(factors=200, regularization=0.001)\n",
    "wrmf.fit(data.T*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CNN_Dataset(Dataset):\n",
    "    def __init__(self, data, als_model):\n",
    "        self.input_data = data\n",
    "        self.als_model = als_model\n",
    "        self.songs_embeddings = als_model.item_factors\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.input_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.als_model.recommend(idx, self.input_data, N=1000)\n",
    "        idx_list = [idx for idx, _ in rec]\n",
    "        negative_list = [i for i in range(self.input_data.shape[1]) if i not in idx_list]\n",
    "        negative_list = random.sample(negative_list, 200)\n",
    "        data = torch.FloatTensor(np.reshape(self.songs_embeddings[idx_list], (200, -1, 1)))\n",
    "        negative = torch.FloatTensor(np.reshape(self.songs_embeddings[negative_list], (200, -1, 1)))\n",
    "        return data, negative\n",
    "    \n",
    "#Loss텀을 위해서 후보군 1000개와 후보군에 속하지 않은 곡 200개를 뽑음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset=CNN_Dataset(data, wrmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset,batch_size=1,shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후보군 :  torch.Size([1, 200, 1000, 1])\n",
      "후보군이 아닌 것 :  torch.Size([1, 200, 200, 1])\n",
      "CPU times: user 1min 52s, sys: 477 ms, total: 1min 52s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "candidate, negative = next(iter(trainloader))\n",
    "print(\"후보군 : \", candidate.shape)\n",
    "print(\"후보군이 아닌 것 : \", negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as weight_init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('use: ',device)\n",
    "\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels*2,\n",
    "            kernel_size=(3,1),\n",
    "            padding=(1,0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out, gate = out.split(int(out.shape[1] / 2), 1)\n",
    "        out = out * torch.sigmoid(gate)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, layer_size=7, embedding_size=200, output_size=900):\n",
    "    #layer_sizes : a number of GLU block \n",
    "        super(CNN, self).__init__()\n",
    "        self.GLU = self._make_layer(layer_size, embedding_size, output_size)\n",
    "        self.FCL = nn.Linear(output_size*3, 200)\n",
    "    \n",
    "    def _make_layer(self, layer_size, embedding_size, output_size):\n",
    "        layers = []\n",
    "        for i in range(layer_size-1):\n",
    "            if i==0:\n",
    "                layers.append(GLU(\n",
    "                    in_channels=embedding_size, \n",
    "                    out_channels=output_size\n",
    "                ))\n",
    "            else:\n",
    "                layers.append(GLU(\n",
    "                    in_channels=output_size, \n",
    "                    out_channels=output_size\n",
    "                ))\n",
    "            layers.append(nn.BatchNorm2d(output_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.GLU(x)\n",
    "        out = torch.topk(out, k=3, dim=2)[0]\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.FCL(out)\n",
    "        out = torch.unsqueeze(out, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (GLU): Sequential(\n",
       "    (0): GLU(\n",
       "      (conv): Conv2d(200, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (1): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): GLU(\n",
       "      (conv): Conv2d(900, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (4): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): GLU(\n",
       "      (conv): Conv2d(900, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (7): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): GLU(\n",
       "      (conv): Conv2d(900, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (10): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): GLU(\n",
       "      (conv): Conv2d(900, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (13): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): GLU(\n",
       "      (conv): Conv2d(900, 1800, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "    )\n",
       "    (16): BatchNorm2d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU()\n",
       "  )\n",
       "  (FCL): Linear(in_features=2700, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=CNN(7, 200, 900)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(data, negative, pred, k):\n",
    "    out1 = torch.bmm(pred,torch.squeeze(data, -1)[:,:,:k])\n",
    "    out1 = torch.log(1/(torch.exp(-out1)+1))\n",
    "    out1 = -torch.sum(out1)\n",
    "    out2 = torch.bmm(pred,torch.squeeze(negative, -1))\n",
    "    out2 = torch.log(1-1/(torch.exp(-out2)+1))\n",
    "    out2 = -torch.sum(out2) \n",
    "    return (out1+out2)/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def train(model, trainloader, optimizer, loss_fn, k=200, n_epoch=10):\n",
    "    model.train()\n",
    "    pbar = trange(n_epoch, desc='Loss : 0', leave=True, position=0)\n",
    "    for epoch in pbar:\n",
    "        for X, Y in trainloader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            pred = model(X) \n",
    "            loss = loss_fn(X, Y, pred, k)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description(\"Loss : %.3f\" % loss)\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 269.689:   0%|          | 0/1 [1:29:22<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, optimizer, loss_fn, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
